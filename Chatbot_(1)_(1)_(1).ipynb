{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c071dfb",
      "metadata": {
        "id": "3c071dfb"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rZ_kMMbqVKXF",
      "metadata": {
        "id": "rZ_kMMbqVKXF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jGYEoEnWSnpc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGYEoEnWSnpc",
        "outputId": "b8aae746-1191-47ae-8fbf-cecce61d0666"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\saurabh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03459b8f",
      "metadata": {
        "id": "03459b8f",
        "outputId": "e6245dca-7c9b-4347-8ddf-ab3a8fd47182"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\saurabh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1bc94eb",
      "metadata": {
        "id": "e1bc94eb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4622b682",
      "metadata": {
        "id": "4622b682",
        "outputId": "90799d15-d4b4-4621-b4e5-ba2e0467a26f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(198,\n",
              " ['a',\n",
              "  'about',\n",
              "  'above',\n",
              "  'after',\n",
              "  'again',\n",
              "  'against',\n",
              "  'ain',\n",
              "  'all',\n",
              "  'am',\n",
              "  'an'])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "len(stop_words),stop_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d27601",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4d27601",
        "outputId": "e0398490-5c0f-4f65-81e3-f18c9d37ec92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi there',\n",
              "    'How are you? ',\n",
              "    'Is anyone there?',\n",
              "    'Hey',\n",
              "    'Hola',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hi there, how can I help?',\n",
              "    'Welcome to our web portal',\n",
              "    'Good Day']},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['Bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'Nice chatting to you, bye',\n",
              "    'Till next time'],\n",
              "   'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Awesome, thanks',\n",
              "    'Thanks for helping me'],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
              "  {'tag': 'noanswer',\n",
              "   'patterns': [],\n",
              "   'responses': [\"Sorry, can't understand you\",\n",
              "    'Please give me more info',\n",
              "    'Not sure I understand']},\n",
              "  {'tag': 'options',\n",
              "   'patterns': ['How you could help me?',\n",
              "    'What you can do?',\n",
              "    'What help you provide?',\n",
              "    'How you can be helpful?',\n",
              "    'What support is offered'],\n",
              "   'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies',\n",
              "    'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'adverse_drug',\n",
              "   'patterns': ['How to check Adverse drug reaction?',\n",
              "    'Open adverse drugs module',\n",
              "    'Give me a list of drugs causing adverse behavior',\n",
              "    'List all drugs suitable for patient with adverse reaction',\n",
              "    'Which drugs dont have adverse reaction?'],\n",
              "   'responses': ['Navigating to Adverse drug reaction module'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'blood_pressure',\n",
              "   'patterns': ['Open blood pressure module',\n",
              "    'Task related to blood pressure',\n",
              "    'Blood pressure data entry',\n",
              "    'I want to log blood pressure results',\n",
              "    'Blood pressure data management',\n",
              "    'cricket score'],\n",
              "   'responses': ['Navigating to Blood Pressure module'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'blood_pressure_search',\n",
              "   'patterns': ['I want to search for blood pressure result history',\n",
              "    'Blood pressure for patient',\n",
              "    'Load patient blood pressure result',\n",
              "    'Show blood pressure results for patient',\n",
              "    'Find blood pressure results by ID'],\n",
              "   'responses': ['Please provide Patient ID', 'Patient ID?'],\n",
              "   'context': ['search_blood_pressure_by_patient_id']},\n",
              "  {'tag': 'search_blood_pressure_by_patient_id',\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading Blood pressure result for Patient'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'pharmacy_search',\n",
              "   'patterns': ['Find me a pharmacy',\n",
              "    'Find pharmacy',\n",
              "    'List of pharmacies nearby',\n",
              "    'Locate pharmacy',\n",
              "    'Search pharmacy'],\n",
              "   'responses': ['Please provide pharmacy name'],\n",
              "   'context': ['search_pharmacy_by_name']},\n",
              "  {'tag': 'search_pharmacy_by_name',\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading pharmacy details'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'hospital_search',\n",
              "   'patterns': ['Lookup for hospital',\n",
              "    'Searching for hospital to transfer patient',\n",
              "    'I want to search hospital data',\n",
              "    'Hospital lookup for patient',\n",
              "    'Looking up hospital details',\n",
              "    'movie review'],\n",
              "   'responses': ['Please provide hospital name or location'],\n",
              "   'context': ['search_hospital_by_params']},\n",
              "  {'tag': 'search_hospital_by_params',\n",
              "   'patterns': [],\n",
              "   'responses': ['Please provide hospital type'],\n",
              "   'context': ['search_hospital_by_type']},\n",
              "  {'tag': 'search_hospital_by_type',\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading hospital details'],\n",
              "   'context': ['']}]}"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "#data_file = open('intents.json').read()\n",
        "data_file=open('C:/Data/intents.json').read()\n",
        "intents = json.loads(data_file)\n",
        "intents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcff8be7",
      "metadata": {
        "id": "fcff8be7"
      },
      "outputs": [],
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each word\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        #add documents in the corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cntBzbOIWCsU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cntBzbOIWCsU",
        "outputId": "ba152812-a2ba-4f0a-9836-48c5362b4f12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words.count('?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dt1D4MRkWcvO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt1D4MRkWcvO",
        "outputId": "f832bb83-b8da-4a62-d381-002da3398f32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'there',\n",
              " 'How',\n",
              " 'are',\n",
              " 'you',\n",
              " '?',\n",
              " 'Is',\n",
              " 'anyone',\n",
              " 'there',\n",
              " '?',\n",
              " 'Hey',\n",
              " 'Hola',\n",
              " 'Hello',\n",
              " 'Good',\n",
              " 'day',\n",
              " 'Bye',\n",
              " 'See',\n",
              " 'you',\n",
              " 'later',\n",
              " 'Goodbye',\n",
              " 'Nice',\n",
              " 'chatting',\n",
              " 'to',\n",
              " 'you',\n",
              " ',',\n",
              " 'bye',\n",
              " 'Till',\n",
              " 'next',\n",
              " 'time',\n",
              " 'Thanks',\n",
              " 'Thank',\n",
              " 'you',\n",
              " 'That',\n",
              " \"'s\",\n",
              " 'helpful',\n",
              " 'Awesome',\n",
              " ',',\n",
              " 'thanks',\n",
              " 'Thanks',\n",
              " 'for',\n",
              " 'helping',\n",
              " 'me',\n",
              " 'How',\n",
              " 'you',\n",
              " 'could',\n",
              " 'help',\n",
              " 'me',\n",
              " '?',\n",
              " 'What',\n",
              " 'you',\n",
              " 'can',\n",
              " 'do',\n",
              " '?',\n",
              " 'What',\n",
              " 'help',\n",
              " 'you',\n",
              " 'provide',\n",
              " '?',\n",
              " 'How',\n",
              " 'you',\n",
              " 'can',\n",
              " 'be',\n",
              " 'helpful',\n",
              " '?',\n",
              " 'What',\n",
              " 'support',\n",
              " 'is',\n",
              " 'offered',\n",
              " 'How',\n",
              " 'to',\n",
              " 'check',\n",
              " 'Adverse',\n",
              " 'drug',\n",
              " 'reaction',\n",
              " '?',\n",
              " 'Open',\n",
              " 'adverse',\n",
              " 'drugs',\n",
              " 'module',\n",
              " 'Give',\n",
              " 'me',\n",
              " 'a',\n",
              " 'list',\n",
              " 'of',\n",
              " 'drugs',\n",
              " 'causing',\n",
              " 'adverse',\n",
              " 'behavior',\n",
              " 'List',\n",
              " 'all',\n",
              " 'drugs',\n",
              " 'suitable',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'with',\n",
              " 'adverse',\n",
              " 'reaction',\n",
              " 'Which',\n",
              " 'drugs',\n",
              " 'dont',\n",
              " 'have',\n",
              " 'adverse',\n",
              " 'reaction',\n",
              " '?',\n",
              " 'Open',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'module',\n",
              " 'Task',\n",
              " 'related',\n",
              " 'to',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'data',\n",
              " 'entry',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'log',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'data',\n",
              " 'management',\n",
              " 'cricket',\n",
              " 'score',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'search',\n",
              " 'for',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'result',\n",
              " 'history',\n",
              " 'Blood',\n",
              " 'pressure',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Load',\n",
              " 'patient',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'result',\n",
              " 'Show',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Find',\n",
              " 'blood',\n",
              " 'pressure',\n",
              " 'results',\n",
              " 'by',\n",
              " 'ID',\n",
              " 'Find',\n",
              " 'me',\n",
              " 'a',\n",
              " 'pharmacy',\n",
              " 'Find',\n",
              " 'pharmacy',\n",
              " 'List',\n",
              " 'of',\n",
              " 'pharmacies',\n",
              " 'nearby',\n",
              " 'Locate',\n",
              " 'pharmacy',\n",
              " 'Search',\n",
              " 'pharmacy',\n",
              " 'Lookup',\n",
              " 'for',\n",
              " 'hospital',\n",
              " 'Searching',\n",
              " 'for',\n",
              " 'hospital',\n",
              " 'to',\n",
              " 'transfer',\n",
              " 'patient',\n",
              " 'I',\n",
              " 'want',\n",
              " 'to',\n",
              " 'search',\n",
              " 'hospital',\n",
              " 'data',\n",
              " 'Hospital',\n",
              " 'lookup',\n",
              " 'for',\n",
              " 'patient',\n",
              " 'Looking',\n",
              " 'up',\n",
              " 'hospital',\n",
              " 'details',\n",
              " 'movie',\n",
              " 'review']"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q6gFJkzBVNPR",
      "metadata": {
        "id": "q6gFJkzBVNPR"
      },
      "outputs": [],
      "source": [
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YqpPp-8TV325",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqpPp-8TV325",
        "outputId": "f2f87e30-3924-43ab-c79d-32ccb2abf352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sorted(list(set(words)))) #88"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CvEs8dZ-Xc_r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvEs8dZ-Xc_r",
        "outputId": "a979da64-3da4-4daa-c9eb-40b9644d843b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['adverse_drug',\n",
              " 'blood_pressure',\n",
              " 'blood_pressure_search',\n",
              " 'goodbye',\n",
              " 'greeting',\n",
              " 'hospital_search',\n",
              " 'options',\n",
              " 'pharmacy_search',\n",
              " 'thanks']"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c8eb43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27c8eb43",
        "outputId": "1cf3cdc7-d40e-4bcc-84f5-6c9ed15f6cf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# lemmatize, lower each word and remove duplicates\\nwords = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\\nwords = sorted(list(set(words)))\\n# sort classes\\nclasses = sorted(list(set(classes)))\\n# documents = combination between patterns and intents\\nprint (len(documents), \"documents\")\\n# classes = intents\\nprint (len(classes), \"classes\", classes)\\n# words = all words, vocabulary\\nprint (len(words), \"unique lemmatized words\", words)\\npickle.dump(words,open(\\'words.pkl\\',\\'wb\\'))'"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# lemmatize, lower each word and remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "pickle.dump(words,open('words.pkl','wb'))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c07b188-39d7-4179-b9ab-1cd65b1b23d0",
      "metadata": {
        "id": "9c07b188-39d7-4179-b9ab-1cd65b1b23d0",
        "outputId": "ce0c10ea-0e3d-42d9-c557-29e7335cf5ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49 documents\n",
            "9 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
            "92 unique lemmatized words [\"'s\", ',', 'a', 'adverse', 'all', 'anyone', 'are', 'awesome', 'be', 'behavior', 'blood', 'by', 'bye', 'can', 'causing', 'chatting', 'check', 'could', 'cricket', 'data', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'give', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'history', 'hola', 'hospital', 'how', 'i', 'id', 'is', 'later', 'list', 'load', 'locate', 'log', 'looking', 'lookup', 'management', 'me', 'module', 'movie', 'nearby', 'next', 'nice', 'of', 'offered', 'open', 'patient', 'pharmacy', 'pressure', 'provide', 'reaction', 'related', 'result', 'review', 'score', 'search', 'searching', 'see', 'show', 'suitable', 'support', 'task', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'transfer', 'up', 'want', 'what', 'which', 'with', 'you']\n"
          ]
        }
      ],
      "source": [
        "# lemmatize, lower each word and remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "pickle.dump(words,open('C:/Data/Chatbot/words.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MlY7cl3gaznN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlY7cl3gaznN",
        "outputId": "2585a3fd-4322-493c-c0d3-9bbfed9418df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['how', 'are', 'you']"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[w.lower() for w in documents[1][0] if w.lower() in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vWW1L4GwcM9q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWW1L4GwcM9q",
        "outputId": "d9b22546-cae3-4d92-d6d2-afe1d0f1f115"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"'s\",\n",
              " ',',\n",
              " 'a',\n",
              " 'adverse',\n",
              " 'all',\n",
              " 'anyone',\n",
              " 'are',\n",
              " 'awesome',\n",
              " 'be',\n",
              " 'behavior',\n",
              " 'blood',\n",
              " 'by',\n",
              " 'bye',\n",
              " 'can',\n",
              " 'causing',\n",
              " 'chatting',\n",
              " 'check',\n",
              " 'could',\n",
              " 'cricket',\n",
              " 'data',\n",
              " 'day',\n",
              " 'detail',\n",
              " 'do',\n",
              " 'dont',\n",
              " 'drug',\n",
              " 'entry',\n",
              " 'find',\n",
              " 'for',\n",
              " 'give',\n",
              " 'good',\n",
              " 'goodbye',\n",
              " 'have',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'helpful',\n",
              " 'helping',\n",
              " 'hey',\n",
              " 'hi',\n",
              " 'history',\n",
              " 'hola',\n",
              " 'hospital',\n",
              " 'how',\n",
              " 'i',\n",
              " 'id',\n",
              " 'is',\n",
              " 'later',\n",
              " 'list',\n",
              " 'load',\n",
              " 'locate',\n",
              " 'log',\n",
              " 'looking',\n",
              " 'lookup',\n",
              " 'management',\n",
              " 'me',\n",
              " 'module',\n",
              " 'movie',\n",
              " 'nearby',\n",
              " 'next',\n",
              " 'nice',\n",
              " 'of',\n",
              " 'offered',\n",
              " 'open',\n",
              " 'patient',\n",
              " 'pharmacy',\n",
              " 'pressure',\n",
              " 'provide',\n",
              " 'reaction',\n",
              " 'related',\n",
              " 'result',\n",
              " 'review',\n",
              " 'score',\n",
              " 'search',\n",
              " 'searching',\n",
              " 'see',\n",
              " 'show',\n",
              " 'suitable',\n",
              " 'support',\n",
              " 'task',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'that',\n",
              " 'there',\n",
              " 'till',\n",
              " 'time',\n",
              " 'to',\n",
              " 'transfer',\n",
              " 'up',\n",
              " 'want',\n",
              " 'what',\n",
              " 'which',\n",
              " 'with',\n",
              " 'you']"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ae8c69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ae8c69",
        "outputId": "27de0565-24b6-44ac-aaed-a321ea7832ce"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (49, 2) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[123], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     training\u001b[38;5;241m.\u001b[39mappend([bag, output_row])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# shuffle our features and turn into np.array\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#random.shuffle(training)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m training \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(training)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# create train and test lists. X - patterns, Y - intents\u001b[39;00m\n\u001b[0;32m     24\u001b[0m train_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(training[:,\u001b[38;5;241m0\u001b[39m])\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (49, 2) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "# create our training data\n",
        "training = []\n",
        "# create an empty array for our output\n",
        "output_empty = [0] * len(classes)\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array with 1, if word match found in current pattern\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])\n",
        "# shuffle our features and turn into np.array\n",
        "#random.shuffle(training)\n",
        "training = np.array(training)\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data created\")\n",
        "print(len(train_x[0]))\n",
        "print(len(train_y[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94468fbc-6692-4a11-94f1-22289f98c405",
      "metadata": {
        "id": "94468fbc-6692-4a11-94f1-22289f98c405",
        "outputId": "1ffe9d69-1f59-4833-b731-afb0fbf11897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data created successfully!\n"
          ]
        }
      ],
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "for doc in documents:\n",
        "    bag = []\n",
        "    pattern_words = doc[0]  # Tokenized sentence\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])\n",
        "# shuffle our features and turn into np.array\n",
        "#random.shuffle(training)\n",
        "import random\n",
        "random.shuffle(training)\n",
        "\n",
        "train_x = np.array([i[0] for i in training], dtype=np.float32)\n",
        "train_y = np.array([i[1] for i in training], dtype=np.float32)\n",
        "\n",
        "print(\"Training data created successfully!\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260be35a-56df-41f5-b672-05a0e75c6aac",
      "metadata": {
        "id": "260be35a-56df-41f5-b672-05a0e75c6aac",
        "outputId": "87e40c8c-c3e2-4599-a2e6-a10e66486eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_x[10]).count(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_NsKmwbSclwM",
      "metadata": {
        "id": "_NsKmwbSclwM"
      },
      "outputs": [],
      "source": [
        "#train_x[10].count(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mQh3hhzTd0fw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQh3hhzTd0fw",
        "outputId": "d5e982f4-eb4d-46e1-c469-62c509fe377e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nice', 'chatting', 'to', 'you', ',', 'bye']"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[w.lower() for w in documents[10][0] if w.lower() in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZtmQ5dLmdYpx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZtmQ5dLmdYpx",
        "outputId": "ec0a05a4-12c6-4e31-a606-c6742af4c3d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'you'"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90d7f45",
      "metadata": {
        "id": "c90d7f45",
        "outputId": "ad1b2fe6-03bc-4bf1-8780-78b4114f8fb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((49, 92), (49, 9))"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(train_x).shape,np.array(train_y).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7095ae",
      "metadata": {
        "id": "af7095ae",
        "outputId": "34e81366-00b0-43d3-8640-252fbfd1a49a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train_x[7].count(1)\n",
        "list(train_x[7]).count(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6726291",
      "metadata": {
        "id": "a6726291",
        "outputId": "3aeb72f5-e80a-488f-a80e-2a92a302ba27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#train_y[7]\n",
        "train_y[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22122f24",
      "metadata": {
        "id": "22122f24",
        "outputId": "1ea99ceb-ae9b-4ce6-aa1c-11cb5c0b3434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['adverse_drug',\n",
              " 'blood_pressure',\n",
              " 'blood_pressure_search',\n",
              " 'goodbye',\n",
              " 'greeting',\n",
              " 'hospital_search',\n",
              " 'options',\n",
              " 'pharmacy_search',\n",
              " 'thanks']"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e68f2db",
      "metadata": {
        "id": "3e68f2db",
        "outputId": "fae7e645-d77f-4951-98ce-9e2a1ce25e49"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                   </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">11,904</span> │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │\n",
              "└────────────────────────────────┴────────────────────────┴──────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m11,904\u001b[0m │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │            \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m8,256\u001b[0m │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m0\u001b[0m │\n",
              "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │          \u001b[38;5;34m585\u001b[0m │\n",
              "└────────────────────────────────┴────────────────────────┴──────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,745</span> (81.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,745\u001b[0m (81.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,745</span> (81.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,745\u001b[0m (81.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ba66fb",
      "metadata": {
        "id": "51ba66fb",
        "outputId": "f6824445-149b-41cc-e6c5-bb484a663e4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11392"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "88*128+128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74c2b2c",
      "metadata": {
        "id": "d74c2b2c",
        "outputId": "30421d87-8a90-4c2a-bdff-fa3225a5a0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 3s 99ms/step - loss: 2.2181 - accuracy: 0.0269 - val_loss: 2.2124 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1752 - accuracy: 0.1111 - val_loss: 2.1987 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.1135 - accuracy: 0.2479 - val_loss: 2.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1074 - accuracy: 0.2095 - val_loss: 2.1710 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9546 - accuracy: 0.3657 - val_loss: 2.1663 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.9578 - accuracy: 0.2810 - val_loss: 2.1564 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8767 - accuracy: 0.4753 - val_loss: 2.1459 - val_accuracy: 0.2000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8212 - accuracy: 0.4033 - val_loss: 2.1288 - val_accuracy: 0.4000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7683 - accuracy: 0.4196 - val_loss: 2.1126 - val_accuracy: 0.4000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6867 - accuracy: 0.5690 - val_loss: 2.0933 - val_accuracy: 0.4000\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.7007 - accuracy: 0.5051 - val_loss: 2.0713 - val_accuracy: 0.4000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.7914 - accuracy: 0.3928 - val_loss: 2.0534 - val_accuracy: 0.4000\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6082 - accuracy: 0.5824 - val_loss: 2.0400 - val_accuracy: 0.4000\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6583 - accuracy: 0.5067 - val_loss: 2.0173 - val_accuracy: 0.4000\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5435 - accuracy: 0.5646 - val_loss: 1.9812 - val_accuracy: 0.4000\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4919 - accuracy: 0.6700 - val_loss: 1.9301 - val_accuracy: 0.4000\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.4547 - accuracy: 0.5836 - val_loss: 1.8958 - val_accuracy: 0.4000\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1745 - accuracy: 0.7527 - val_loss: 1.8477 - val_accuracy: 0.4000\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.3230 - accuracy: 0.6145 - val_loss: 1.8130 - val_accuracy: 0.4000\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1713 - accuracy: 0.7119 - val_loss: 1.7766 - val_accuracy: 0.4000\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2327 - accuracy: 0.6918 - val_loss: 1.7244 - val_accuracy: 0.4000\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0558 - accuracy: 0.8062 - val_loss: 1.6792 - val_accuracy: 0.4000\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1112 - accuracy: 0.7548 - val_loss: 1.6314 - val_accuracy: 0.6000\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0443 - accuracy: 0.7443 - val_loss: 1.5835 - val_accuracy: 0.6000\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9160 - accuracy: 0.8595 - val_loss: 1.5085 - val_accuracy: 0.6000\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.0280 - accuracy: 0.7873 - val_loss: 1.4544 - val_accuracy: 0.8000\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7886 - accuracy: 0.8677 - val_loss: 1.4119 - val_accuracy: 0.8000\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8052 - accuracy: 0.9590 - val_loss: 1.3403 - val_accuracy: 0.8000\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7888 - accuracy: 0.7964 - val_loss: 1.2627 - val_accuracy: 0.8000\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.5940 - accuracy: 0.9528 - val_loss: 1.2037 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.7865 - val_loss: 1.1495 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6590 - accuracy: 0.9125 - val_loss: 1.0770 - val_accuracy: 1.0000\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.9534 - val_loss: 1.0313 - val_accuracy: 1.0000\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5390 - accuracy: 0.9865 - val_loss: 1.0169 - val_accuracy: 0.8000\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4900 - accuracy: 0.9245 - val_loss: 0.9690 - val_accuracy: 0.8000\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4868 - accuracy: 0.8701 - val_loss: 0.9396 - val_accuracy: 0.8000\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5588 - accuracy: 0.9409 - val_loss: 0.9036 - val_accuracy: 0.8000\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4427 - accuracy: 0.9865 - val_loss: 0.8745 - val_accuracy: 0.8000\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.9627 - val_loss: 0.8409 - val_accuracy: 0.8000\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4780 - accuracy: 0.8985 - val_loss: 0.8217 - val_accuracy: 0.8000\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.8825 - val_loss: 0.7778 - val_accuracy: 0.8000\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4771 - accuracy: 0.7918 - val_loss: 0.7490 - val_accuracy: 0.8000\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.9109 - val_loss: 0.7283 - val_accuracy: 0.8000\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.9019 - val_loss: 0.7045 - val_accuracy: 0.8000\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3583 - accuracy: 0.9409 - val_loss: 0.6818 - val_accuracy: 0.8000\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3862 - accuracy: 0.9709 - val_loss: 0.6769 - val_accuracy: 0.8000\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.8000\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2770 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8000\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.2978 - accuracy: 0.9825 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2637 - accuracy: 0.9409 - val_loss: 0.6237 - val_accuracy: 0.8000\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1851 - accuracy: 0.9775 - val_loss: 0.6076 - val_accuracy: 0.8000\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1980 - accuracy: 0.9775 - val_loss: 0.5655 - val_accuracy: 0.8000\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 0.9825 - val_loss: 0.5367 - val_accuracy: 0.8000\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.8000\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1799 - accuracy: 0.9818 - val_loss: 0.5223 - val_accuracy: 0.8000\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2627 - accuracy: 0.9474 - val_loss: 0.5184 - val_accuracy: 0.8000\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1798 - accuracy: 0.9609 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
            "Epoch 59/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1687 - accuracy: 0.9709 - val_loss: 0.5227 - val_accuracy: 0.8000\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8000\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2469 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8000\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1995 - accuracy: 0.9536 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.8000\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8000\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.8000\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2380 - accuracy: 0.9724 - val_loss: 0.4268 - val_accuracy: 0.8000\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8000\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8000\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 1.00 - 0s 9ms/step - loss: 0.1186 - accuracy: 0.9952 - val_loss: 0.3959 - val_accuracy: 0.8000\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8000\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1287 - accuracy: 0.9709 - val_loss: 0.4098 - val_accuracy: 0.8000\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1467 - accuracy: 0.9508 - val_loss: 0.4381 - val_accuracy: 0.8000\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.9865 - val_loss: 0.4286 - val_accuracy: 0.8000\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.8000\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9927 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8000\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8000\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9927 - val_loss: 0.4144 - val_accuracy: 0.8000\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1469 - accuracy: 0.9927 - val_loss: 0.4123 - val_accuracy: 0.8000\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8000\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8000\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.8000\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9709 - val_loss: 0.4770 - val_accuracy: 0.8000\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1667 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8000\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9775 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8000\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8000\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.8000\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1679 - accuracy: 0.9709 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0893 - accuracy: 0.9927 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 10ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8000\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1263 - accuracy: 0.9764 - val_loss: 0.4021 - val_accuracy: 0.8000\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.8000\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.9927 - val_loss: 0.3582 - val_accuracy: 0.8000\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.8000\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8000\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8000\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.8000\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.8000\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1224 - accuracy: 0.9865 - val_loss: 0.2511 - val_accuracy: 0.8000\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.8000\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.8000\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.8000\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.8000\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.8000\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0606 - accuracy: 0.9709 - val_loss: 0.2457 - val_accuracy: 0.8000\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8000\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.8000\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.8000\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.8000\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0970 - accuracy: 0.9409 - val_loss: 0.2710 - val_accuracy: 0.8000\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.8000\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9899 - val_loss: 0.2902 - val_accuracy: 0.8000\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.8000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.8000\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.8000\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8000\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9865 - val_loss: 0.3006 - val_accuracy: 0.8000\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2100 - accuracy: 0.9010 - val_loss: 0.4030 - val_accuracy: 0.8000\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8000\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.5509 - val_accuracy: 0.8000\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8000\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.8000\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9409 - val_loss: 0.4056 - val_accuracy: 0.8000\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.8000\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8000\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8000\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8000\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.8000\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8000\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8000\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8000\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8000\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8000\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8000\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9927 - val_loss: 0.4344 - val_accuracy: 0.8000\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8000\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.8000\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8000\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0810 - accuracy: 0.9274 - val_loss: 0.3839 - val_accuracy: 0.8000\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.8000\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.8000\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.9609 - val_loss: 0.3453 - val_accuracy: 0.8000\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8000\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 1.00 - 0s 10ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.8000\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.8000\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.8000\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1024 - accuracy: 0.9409 - val_loss: 0.3630 - val_accuracy: 0.8000\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.8000\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8000\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.8000\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.8000\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.8000\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.8000\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.8000\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.8000\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8000\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8000\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.8000\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8000\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8000\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8000\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.8000\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.8000\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.8000\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.8000\n",
            "Epoch 174/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.8000\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8000\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.8000\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.8000\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.8000\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8000\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.8000\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8000\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8000\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8000\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9927 - val_loss: 0.4811 - val_accuracy: 0.8000\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9899 - val_loss: 0.4926 - val_accuracy: 0.8000\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5704 - val_accuracy: 0.8000\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8000\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.8000\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.8000\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8000\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.8000\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.8000\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.8000\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.8000\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8000\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.8000\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.8000\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.8000\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8000\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.8000\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.8000\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 0.9865 - val_loss: 0.2521 - val_accuracy: 0.8000\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8000\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.8000\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.8000\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.8000\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.8000\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.8000\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.8000\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.8000\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.8000\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.8000\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.8000\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.8000\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.8000\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.8000\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.8000\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9409 - val_loss: 0.2505 - val_accuracy: 0.8000\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.8000\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.8000\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.8000\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.8000\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.8000\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1361 - accuracy: 0.9409 - val_loss: 0.2499 - val_accuracy: 0.8000\n",
            "Epoch 232/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.8000\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8000\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.8000\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.8000\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.8000\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.8000\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.8000\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.8000\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.8000\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.8000\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.8000\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.8000\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.8000\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.8000\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.8000\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.8000\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.8000\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.8000\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.8000\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.8000\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.8000\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.8000\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.8000\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.8000\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.8000\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.8000\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.8000\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.8000\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 0.9865 - val_loss: 0.3503 - val_accuracy: 0.8000\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.8000\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9865 - val_loss: 0.3589 - val_accuracy: 0.8000\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.8000\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.8000\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.8000\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8000\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8000\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.8000\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8000\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8000\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.8000\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.8000\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.8000\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.8000\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0380 - accuracy: 0.9709 - val_loss: 0.2944 - val_accuracy: 0.8000\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.8000\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.8000\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8000\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0616 - accuracy: 0.9709 - val_loss: 0.2232 - val_accuracy: 0.8000\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.8000\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.1764 - val_accuracy: 0.8000\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.8000\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.8000\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.8000\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.8000\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.8000\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.8000\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.8000\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 0.9825 - val_loss: 0.1673 - val_accuracy: 0.8000\n",
            "Epoch 290/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.8000\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.8000\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.8000\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.8000\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.8000\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.8000\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.8000\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.8000\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9899 - val_loss: 0.2098 - val_accuracy: 0.8000\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.8000\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.2020 - val_accuracy: 0.8000\n",
            "model created\n"
          ]
        }
      ],
      "source": [
        "'''model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=300, batch_size=5, validation_split=0.1)\n",
        "model.save('d:/chatbot/chatbot_model.h5', hist)\n",
        "print(\"model created\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7699bbe4-352c-4e0b-afea-e1400ea4a01a",
      "metadata": {
        "id": "7699bbe4-352c-4e0b-afea-e1400ea4a01a",
        "outputId": "e1f878df-6f3d-403d-e7ad-dba67b81c050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.0899 - loss: 2.2515 - val_accuracy: 0.0000e+00 - val_loss: 2.2742\n",
            "Epoch 2/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1124 - loss: 2.1985 - val_accuracy: 0.0000e+00 - val_loss: 2.2645\n",
            "Epoch 3/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0582 - loss: 2.2252 - val_accuracy: 0.2000 - val_loss: 2.2475\n",
            "Epoch 4/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1646 - loss: 2.1685 - val_accuracy: 0.2000 - val_loss: 2.2368\n",
            "Epoch 5/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3333 - loss: 2.1028 - val_accuracy: 0.2000 - val_loss: 2.2150\n",
            "Epoch 6/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2989 - loss: 2.0014 - val_accuracy: 0.2000 - val_loss: 2.1931\n",
            "Epoch 7/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3469 - loss: 1.9417 - val_accuracy: 0.2000 - val_loss: 2.1779\n",
            "Epoch 8/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3319 - loss: 1.9584 - val_accuracy: 0.2000 - val_loss: 2.1672\n",
            "Epoch 9/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4463 - loss: 1.8890 - val_accuracy: 0.2000 - val_loss: 2.1490\n",
            "Epoch 10/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3652 - loss: 1.8992 - val_accuracy: 0.2000 - val_loss: 2.1280\n",
            "Epoch 11/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3799 - loss: 1.8384 - val_accuracy: 0.4000 - val_loss: 2.0998\n",
            "Epoch 12/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5091 - loss: 1.7458 - val_accuracy: 0.4000 - val_loss: 2.0841\n",
            "Epoch 13/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5711 - loss: 1.7007 - val_accuracy: 0.2000 - val_loss: 2.0589\n",
            "Epoch 14/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4051 - loss: 1.8138 - val_accuracy: 0.2000 - val_loss: 2.0251\n",
            "Epoch 15/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6119 - loss: 1.5254 - val_accuracy: 0.4000 - val_loss: 1.9931\n",
            "Epoch 16/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6093 - loss: 1.4704 - val_accuracy: 0.4000 - val_loss: 1.9574\n",
            "Epoch 17/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5653 - loss: 1.6170 - val_accuracy: 0.6000 - val_loss: 1.8880\n",
            "Epoch 18/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6726 - loss: 1.4594 - val_accuracy: 0.6000 - val_loss: 1.8281\n",
            "Epoch 19/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6779 - loss: 1.4445 - val_accuracy: 0.6000 - val_loss: 1.7951\n",
            "Epoch 20/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6617 - loss: 1.3204 - val_accuracy: 0.6000 - val_loss: 1.7455\n",
            "Epoch 21/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7842 - loss: 1.2225 - val_accuracy: 0.6000 - val_loss: 1.6754\n",
            "Epoch 22/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6434 - loss: 1.2435 - val_accuracy: 0.6000 - val_loss: 1.6081\n",
            "Epoch 23/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8507 - loss: 1.0319 - val_accuracy: 0.6000 - val_loss: 1.5590\n",
            "Epoch 24/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7451 - loss: 1.0785 - val_accuracy: 0.6000 - val_loss: 1.4984\n",
            "Epoch 25/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7087 - loss: 1.0258 - val_accuracy: 0.6000 - val_loss: 1.4541\n",
            "Epoch 26/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9608 - loss: 0.9071 - val_accuracy: 0.6000 - val_loss: 1.4038\n",
            "Epoch 27/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7745 - loss: 0.8694 - val_accuracy: 0.6000 - val_loss: 1.3562\n",
            "Epoch 28/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9027 - loss: 1.0298 - val_accuracy: 0.8000 - val_loss: 1.3194\n",
            "Epoch 29/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9144 - loss: 0.8827 - val_accuracy: 0.8000 - val_loss: 1.2397\n",
            "Epoch 30/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9051 - loss: 0.8552 - val_accuracy: 0.8000 - val_loss: 1.1809\n",
            "Epoch 31/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7228 - loss: 0.8753 - val_accuracy: 0.8000 - val_loss: 1.1479\n",
            "Epoch 32/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8850 - loss: 0.6644 - val_accuracy: 0.8000 - val_loss: 1.1056\n",
            "Epoch 33/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9176 - loss: 0.7167 - val_accuracy: 0.8000 - val_loss: 1.0721\n",
            "Epoch 34/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9828 - loss: 0.5014 - val_accuracy: 0.8000 - val_loss: 1.0183\n",
            "Epoch 35/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9533 - loss: 0.5920 - val_accuracy: 0.8000 - val_loss: 0.9752\n",
            "Epoch 36/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9831 - loss: 0.4489 - val_accuracy: 0.8000 - val_loss: 0.9411\n",
            "Epoch 37/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8860 - loss: 0.5944 - val_accuracy: 0.8000 - val_loss: 0.9018\n",
            "Epoch 38/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7940 - loss: 0.6131 - val_accuracy: 0.8000 - val_loss: 0.8664\n",
            "Epoch 39/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9144 - loss: 0.3423 - val_accuracy: 0.8000 - val_loss: 0.8400\n",
            "Epoch 40/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.4613 - val_accuracy: 0.8000 - val_loss: 0.8362\n",
            "Epoch 41/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.3295 - val_accuracy: 0.8000 - val_loss: 0.8372\n",
            "Epoch 42/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9828 - loss: 0.3529 - val_accuracy: 0.8000 - val_loss: 0.8033\n",
            "Epoch 43/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9579 - loss: 0.3284 - val_accuracy: 0.8000 - val_loss: 0.7729\n",
            "Epoch 44/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9822 - loss: 0.3257 - val_accuracy: 0.8000 - val_loss: 0.7428\n",
            "Epoch 45/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8687 - loss: 0.5202 - val_accuracy: 0.8000 - val_loss: 0.7362\n",
            "Epoch 46/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9955 - loss: 0.3073 - val_accuracy: 0.8000 - val_loss: 0.7285\n",
            "Epoch 47/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9778 - loss: 0.2650 - val_accuracy: 0.8000 - val_loss: 0.7273\n",
            "Epoch 48/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.3092 - val_accuracy: 0.8000 - val_loss: 0.7085\n",
            "Epoch 49/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9828 - loss: 0.1825 - val_accuracy: 0.8000 - val_loss: 0.7040\n",
            "Epoch 50/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.2233 - val_accuracy: 0.8000 - val_loss: 0.6928\n",
            "Epoch 51/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9343 - loss: 0.2421 - val_accuracy: 0.8000 - val_loss: 0.6971\n",
            "Epoch 52/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9683 - loss: 0.2553 - val_accuracy: 0.8000 - val_loss: 0.7015\n",
            "Epoch 53/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.2124 - val_accuracy: 0.8000 - val_loss: 0.6863\n",
            "Epoch 54/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.1295 - val_accuracy: 0.8000 - val_loss: 0.6799\n",
            "Epoch 55/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1728 - val_accuracy: 0.8000 - val_loss: 0.6902\n",
            "Epoch 56/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9213 - loss: 0.2960 - val_accuracy: 0.8000 - val_loss: 0.6909\n",
            "Epoch 57/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.2306 - val_accuracy: 0.8000 - val_loss: 0.7001\n",
            "Epoch 58/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.1265 - val_accuracy: 0.8000 - val_loss: 0.6998\n",
            "Epoch 59/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.2166 - val_accuracy: 0.8000 - val_loss: 0.7041\n",
            "Epoch 60/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.2033 - val_accuracy: 0.8000 - val_loss: 0.6962\n",
            "Epoch 61/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.1717 - val_accuracy: 0.8000 - val_loss: 0.6926\n",
            "Epoch 62/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9778 - loss: 0.1923 - val_accuracy: 0.8000 - val_loss: 0.6869\n",
            "Epoch 63/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9341 - loss: 0.2211 - val_accuracy: 0.8000 - val_loss: 0.7157\n",
            "Epoch 64/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9489 - loss: 0.1670 - val_accuracy: 0.8000 - val_loss: 0.7290\n",
            "Epoch 65/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1092 - val_accuracy: 0.8000 - val_loss: 0.7161\n",
            "Epoch 66/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9611 - loss: 0.1545 - val_accuracy: 0.8000 - val_loss: 0.7164\n",
            "Epoch 67/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0832 - val_accuracy: 0.8000 - val_loss: 0.7115\n",
            "Epoch 68/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.1157 - val_accuracy: 0.8000 - val_loss: 0.7145\n",
            "Epoch 69/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.1081 - val_accuracy: 0.8000 - val_loss: 0.7119\n",
            "Epoch 70/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1213 - val_accuracy: 0.8000 - val_loss: 0.7124\n",
            "Epoch 71/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9279 - loss: 0.1705 - val_accuracy: 0.8000 - val_loss: 0.7069\n",
            "Epoch 72/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0940 - val_accuracy: 0.8000 - val_loss: 0.6913\n",
            "Epoch 73/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0792 - val_accuracy: 0.8000 - val_loss: 0.6827\n",
            "Epoch 74/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.1509 - val_accuracy: 0.8000 - val_loss: 0.6665\n",
            "Epoch 75/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.1521 - val_accuracy: 0.8000 - val_loss: 0.6574\n",
            "Epoch 76/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0965 - val_accuracy: 0.8000 - val_loss: 0.6691\n",
            "Epoch 77/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9868 - loss: 0.1302 - val_accuracy: 0.8000 - val_loss: 0.6682\n",
            "Epoch 78/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0954 - val_accuracy: 0.8000 - val_loss: 0.6639\n",
            "Epoch 79/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9868 - loss: 0.0966 - val_accuracy: 0.8000 - val_loss: 0.6567\n",
            "Epoch 80/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1370 - val_accuracy: 0.8000 - val_loss: 0.6478\n",
            "Epoch 81/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0588 - val_accuracy: 0.8000 - val_loss: 0.6364\n",
            "Epoch 82/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0475 - val_accuracy: 0.8000 - val_loss: 0.6239\n",
            "Epoch 83/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.1015 - val_accuracy: 0.8000 - val_loss: 0.6136\n",
            "Epoch 84/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.1136 - val_accuracy: 0.8000 - val_loss: 0.6129\n",
            "Epoch 85/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0827 - val_accuracy: 0.8000 - val_loss: 0.6151\n",
            "Epoch 86/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0918 - val_accuracy: 0.8000 - val_loss: 0.6078\n",
            "Epoch 87/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0710 - val_accuracy: 0.8000 - val_loss: 0.6138\n",
            "Epoch 88/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1124 - val_accuracy: 0.8000 - val_loss: 0.6317\n",
            "Epoch 89/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0840 - val_accuracy: 0.8000 - val_loss: 0.6471\n",
            "Epoch 90/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1605 - val_accuracy: 0.8000 - val_loss: 0.6452\n",
            "Epoch 91/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.1577 - val_accuracy: 0.8000 - val_loss: 0.6449\n",
            "Epoch 92/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9239 - loss: 0.1675 - val_accuracy: 0.8000 - val_loss: 0.6403\n",
            "Epoch 93/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0635 - val_accuracy: 0.8000 - val_loss: 0.6274\n",
            "Epoch 94/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.8000 - val_loss: 0.6150\n",
            "Epoch 95/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9611 - loss: 0.1030 - val_accuracy: 0.8000 - val_loss: 0.6065\n",
            "Epoch 96/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0502 - val_accuracy: 0.8000 - val_loss: 0.5945\n",
            "Epoch 97/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9666 - loss: 0.0946 - val_accuracy: 0.8000 - val_loss: 0.6191\n",
            "Epoch 98/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0736 - val_accuracy: 0.8000 - val_loss: 0.6374\n",
            "Epoch 99/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9901 - loss: 0.0759 - val_accuracy: 0.8000 - val_loss: 0.6375\n",
            "Epoch 100/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0366 - val_accuracy: 0.8000 - val_loss: 0.6298\n",
            "Epoch 101/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0323 - val_accuracy: 0.8000 - val_loss: 0.6257\n",
            "Epoch 102/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9930 - loss: 0.0645 - val_accuracy: 0.8000 - val_loss: 0.6244\n",
            "Epoch 103/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9711 - loss: 0.1086 - val_accuracy: 0.8000 - val_loss: 0.6291\n",
            "Epoch 104/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9611 - loss: 0.0970 - val_accuracy: 0.8000 - val_loss: 0.6153\n",
            "Epoch 105/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9930 - loss: 0.0785 - val_accuracy: 0.8000 - val_loss: 0.6114\n",
            "Epoch 106/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0303 - val_accuracy: 0.8000 - val_loss: 0.6162\n",
            "Epoch 107/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8000 - val_loss: 0.6182\n",
            "Epoch 108/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0338 - val_accuracy: 0.8000 - val_loss: 0.6272\n",
            "Epoch 109/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.8000 - val_loss: 0.6388\n",
            "Epoch 110/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0760 - val_accuracy: 0.8000 - val_loss: 0.6383\n",
            "Epoch 111/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.0919 - val_accuracy: 0.8000 - val_loss: 0.6379\n",
            "Epoch 112/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9930 - loss: 0.0319 - val_accuracy: 0.8000 - val_loss: 0.6372\n",
            "Epoch 113/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 0.8000 - val_loss: 0.6321\n",
            "Epoch 114/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.8000 - val_loss: 0.6291\n",
            "Epoch 115/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0436 - val_accuracy: 0.8000 - val_loss: 0.6282\n",
            "Epoch 116/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0318 - val_accuracy: 0.8000 - val_loss: 0.6219\n",
            "Epoch 117/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9868 - loss: 0.0526 - val_accuracy: 0.8000 - val_loss: 0.6241\n",
            "Epoch 118/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9778 - loss: 0.0467 - val_accuracy: 0.8000 - val_loss: 0.6438\n",
            "Epoch 119/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.8000 - val_loss: 0.6492\n",
            "Epoch 120/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0478 - val_accuracy: 0.8000 - val_loss: 0.6490\n",
            "Epoch 121/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9611 - loss: 0.0931 - val_accuracy: 0.8000 - val_loss: 0.6520\n",
            "Epoch 122/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0617 - val_accuracy: 0.8000 - val_loss: 0.6591\n",
            "Epoch 123/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0719 - val_accuracy: 0.8000 - val_loss: 0.6632\n",
            "Epoch 124/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0500 - val_accuracy: 0.8000 - val_loss: 0.6690\n",
            "Epoch 125/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0827 - val_accuracy: 0.8000 - val_loss: 0.6820\n",
            "Epoch 126/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.8000 - val_loss: 0.6907\n",
            "Epoch 127/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.8000 - val_loss: 0.6877\n",
            "Epoch 128/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9411 - loss: 0.0967 - val_accuracy: 0.8000 - val_loss: 0.6851\n",
            "Epoch 129/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0429 - val_accuracy: 0.8000 - val_loss: 0.6934\n",
            "Epoch 130/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 0.8000 - val_loss: 0.7039\n",
            "Epoch 131/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9189 - loss: 0.1618 - val_accuracy: 0.8000 - val_loss: 0.6925\n",
            "Epoch 132/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0495 - val_accuracy: 0.8000 - val_loss: 0.6831\n",
            "Epoch 133/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.8000 - val_loss: 0.6737\n",
            "Epoch 134/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0358 - val_accuracy: 0.8000 - val_loss: 0.6736\n",
            "Epoch 135/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9411 - loss: 0.1256 - val_accuracy: 0.8000 - val_loss: 0.6935\n",
            "Epoch 136/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.8000 - val_loss: 0.7176\n",
            "Epoch 137/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.8000 - val_loss: 0.7259\n",
            "Epoch 138/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.8000 - val_loss: 0.7306\n",
            "Epoch 139/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 0.8000 - val_loss: 0.7131\n",
            "Epoch 140/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0408 - val_accuracy: 0.8000 - val_loss: 0.7003\n",
            "Epoch 141/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9711 - loss: 0.1002 - val_accuracy: 0.8000 - val_loss: 0.6964\n",
            "Epoch 142/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.8000 - val_loss: 0.6960\n",
            "Epoch 143/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.8000 - val_loss: 0.6962\n",
            "Epoch 144/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.8000 - val_loss: 0.6942\n",
            "Epoch 145/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0768 - val_accuracy: 0.8000 - val_loss: 0.6873\n",
            "Epoch 146/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0242 - val_accuracy: 0.8000 - val_loss: 0.6897\n",
            "Epoch 147/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 0.8000 - val_loss: 0.6942\n",
            "Epoch 148/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9729 - loss: 0.0742 - val_accuracy: 0.8000 - val_loss: 0.6904\n",
            "Epoch 149/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0220 - val_accuracy: 0.8000 - val_loss: 0.6889\n",
            "Epoch 150/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9778 - loss: 0.0486 - val_accuracy: 0.8000 - val_loss: 0.6873\n",
            "Epoch 151/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0397 - val_accuracy: 0.8000 - val_loss: 0.6878\n",
            "Epoch 152/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.8000 - val_loss: 0.6805\n",
            "Epoch 153/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.8000 - val_loss: 0.6548\n",
            "Epoch 154/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.8000 - val_loss: 0.6385\n",
            "Epoch 155/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8000 - val_loss: 0.6341\n",
            "Epoch 156/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9778 - loss: 0.0385 - val_accuracy: 0.8000 - val_loss: 0.6390\n",
            "Epoch 157/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9828 - loss: 0.0448 - val_accuracy: 0.8000 - val_loss: 0.6400\n",
            "Epoch 158/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9711 - loss: 0.0453 - val_accuracy: 0.8000 - val_loss: 0.6269\n",
            "Epoch 159/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.8000 - val_loss: 0.6185\n",
            "Epoch 160/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.8000 - val_loss: 0.6207\n",
            "Epoch 161/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.8000 - val_loss: 0.6227\n",
            "Epoch 162/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8000 - val_loss: 0.6317\n",
            "Epoch 163/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.8000 - val_loss: 0.6430\n",
            "Epoch 164/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.8000 - val_loss: 0.6525\n",
            "Epoch 165/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0141 - val_accuracy: 0.8000 - val_loss: 0.6549\n",
            "Epoch 166/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0611 - val_accuracy: 0.8000 - val_loss: 0.6515\n",
            "Epoch 167/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.8000 - val_loss: 0.6523\n",
            "Epoch 168/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.8000 - val_loss: 0.6649\n",
            "Epoch 169/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0351 - val_accuracy: 0.8000 - val_loss: 0.6646\n",
            "Epoch 170/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.8000 - val_loss: 0.6628\n",
            "Epoch 171/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9828 - loss: 0.0322 - val_accuracy: 0.8000 - val_loss: 0.6553\n",
            "Epoch 172/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8000 - val_loss: 0.6452\n",
            "Epoch 173/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.8000 - val_loss: 0.6424\n",
            "Epoch 174/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.8000 - val_loss: 0.6446\n",
            "Epoch 175/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 0.8000 - val_loss: 0.6443\n",
            "Epoch 176/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.8000 - val_loss: 0.6341\n",
            "Epoch 177/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8000 - val_loss: 0.6286\n",
            "Epoch 178/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.8000 - val_loss: 0.6202\n",
            "Epoch 179/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0269 - val_accuracy: 0.8000 - val_loss: 0.6144\n",
            "Epoch 180/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.8000 - val_loss: 0.6135\n",
            "Epoch 181/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.8000 - val_loss: 0.6155\n",
            "Epoch 182/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 0.8000 - val_loss: 0.6105\n",
            "Epoch 183/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.8000 - val_loss: 0.6024\n",
            "Epoch 184/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.8000 - val_loss: 0.5952\n",
            "Epoch 185/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 0.8000 - val_loss: 0.5884\n",
            "Epoch 186/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.8000 - val_loss: 0.5896\n",
            "Epoch 187/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8000 - val_loss: 0.5973\n",
            "Epoch 188/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.8000 - val_loss: 0.6073\n",
            "Epoch 189/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.8000 - val_loss: 0.6139\n",
            "Epoch 190/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.8000 - val_loss: 0.6200\n",
            "Epoch 191/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.8000 - val_loss: 0.6244\n",
            "Epoch 192/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8000 - val_loss: 0.6261\n",
            "Epoch 193/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.8000 - val_loss: 0.6274\n",
            "Epoch 194/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8000 - val_loss: 0.6394\n",
            "Epoch 195/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.8000 - val_loss: 0.6394\n",
            "Epoch 196/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.8000 - val_loss: 0.6299\n",
            "Epoch 197/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.8000 - val_loss: 0.6233\n",
            "Epoch 198/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0264 - val_accuracy: 0.8000 - val_loss: 0.6105\n",
            "Epoch 199/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9930 - loss: 0.0254 - val_accuracy: 0.8000 - val_loss: 0.5943\n",
            "Epoch 200/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.8000 - val_loss: 0.5853\n",
            "Epoch 201/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8000 - val_loss: 0.5816\n",
            "Epoch 202/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0517 - val_accuracy: 0.8000 - val_loss: 0.5814\n",
            "Epoch 203/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0497 - val_accuracy: 0.8000 - val_loss: 0.6192\n",
            "Epoch 204/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8000 - val_loss: 0.6386\n",
            "Epoch 205/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.8000 - val_loss: 0.6400\n",
            "Epoch 206/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9828 - loss: 0.0384 - val_accuracy: 0.8000 - val_loss: 0.6376\n",
            "Epoch 207/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.8000 - val_loss: 0.6407\n",
            "Epoch 208/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.8000 - val_loss: 0.6486\n",
            "Epoch 209/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.8000 - val_loss: 0.6531\n",
            "Epoch 210/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9901 - loss: 0.0284 - val_accuracy: 0.8000 - val_loss: 0.6589\n",
            "Epoch 211/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0340 - val_accuracy: 0.8000 - val_loss: 0.6613\n",
            "Epoch 212/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8000 - val_loss: 0.6561\n",
            "Epoch 213/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8000 - val_loss: 0.6560\n",
            "Epoch 214/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8000 - val_loss: 0.6578\n",
            "Epoch 215/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8000 - val_loss: 0.6642\n",
            "Epoch 216/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.8000 - val_loss: 0.6662\n",
            "Epoch 217/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8000 - val_loss: 0.6655\n",
            "Epoch 218/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.8000 - val_loss: 0.6644\n",
            "Epoch 219/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0315 - val_accuracy: 0.8000 - val_loss: 0.6721\n",
            "Epoch 220/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.8000 - val_loss: 0.6771\n",
            "Epoch 221/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.8000 - val_loss: 0.6833\n",
            "Epoch 222/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9828 - loss: 0.0273 - val_accuracy: 0.8000 - val_loss: 0.6946\n",
            "Epoch 223/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.8000 - val_loss: 0.7133\n",
            "Epoch 224/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 0.8000 - val_loss: 0.7316\n",
            "Epoch 225/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.8000 - val_loss: 0.7383\n",
            "Epoch 226/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8000 - val_loss: 0.7337\n",
            "Epoch 227/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8000 - val_loss: 0.7276\n",
            "Epoch 228/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.8000 - val_loss: 0.7305\n",
            "Epoch 229/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.8000 - val_loss: 0.7585\n",
            "Epoch 230/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9868 - loss: 0.0455 - val_accuracy: 0.8000 - val_loss: 0.7605\n",
            "Epoch 231/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8000 - val_loss: 0.7501\n",
            "Epoch 232/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8000 - val_loss: 0.7358\n",
            "Epoch 233/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.8000 - val_loss: 0.7277\n",
            "Epoch 234/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8000 - val_loss: 0.7186\n",
            "Epoch 235/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.8000 - val_loss: 0.7068\n",
            "Epoch 236/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0482 - val_accuracy: 0.8000 - val_loss: 0.6904\n",
            "Epoch 237/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8000 - val_loss: 0.6849\n",
            "Epoch 238/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8000 - val_loss: 0.6827\n",
            "Epoch 239/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.8000 - val_loss: 0.6912\n",
            "Epoch 240/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8000 - val_loss: 0.6983\n",
            "Epoch 241/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.8000 - val_loss: 0.7100\n",
            "Epoch 242/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8000 - val_loss: 0.7061\n",
            "Epoch 243/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8000 - val_loss: 0.7061\n",
            "Epoch 244/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0516 - val_accuracy: 0.8000 - val_loss: 0.7010\n",
            "Epoch 245/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8000 - val_loss: 0.7004\n",
            "Epoch 246/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8000 - val_loss: 0.7023\n",
            "Epoch 247/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8000 - val_loss: 0.7050\n",
            "Epoch 248/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8000 - val_loss: 0.7105\n",
            "Epoch 249/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.8000 - val_loss: 0.7165\n",
            "Epoch 250/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8000 - val_loss: 0.7156\n",
            "Epoch 251/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.8000 - val_loss: 0.7096\n",
            "Epoch 252/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8000 - val_loss: 0.7015\n",
            "Epoch 253/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9955 - loss: 0.0219 - val_accuracy: 0.8000 - val_loss: 0.6855\n",
            "Epoch 254/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.8000 - val_loss: 0.6658\n",
            "Epoch 255/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8000 - val_loss: 0.6573\n",
            "Epoch 256/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9930 - loss: 0.0189 - val_accuracy: 0.8000 - val_loss: 0.6531\n",
            "Epoch 257/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.8000 - val_loss: 0.6520\n",
            "Epoch 258/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0406 - val_accuracy: 0.8000 - val_loss: 0.6449\n",
            "Epoch 259/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.8000 - val_loss: 0.6353\n",
            "Epoch 260/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8000 - val_loss: 0.6271\n",
            "Epoch 261/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.8000 - val_loss: 0.6259\n",
            "Epoch 262/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9711 - loss: 0.0317 - val_accuracy: 0.8000 - val_loss: 0.6209\n",
            "Epoch 263/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.8000 - val_loss: 0.6139\n",
            "Epoch 264/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8000 - val_loss: 0.6156\n",
            "Epoch 265/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8000 - val_loss: 0.6166\n",
            "Epoch 266/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.8000 - val_loss: 0.6234\n",
            "Epoch 267/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9828 - loss: 0.0398 - val_accuracy: 0.8000 - val_loss: 0.6153\n",
            "Epoch 268/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8000 - val_loss: 0.6067\n",
            "Epoch 269/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8000 - val_loss: 0.6056\n",
            "Epoch 270/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.8000 - val_loss: 0.5974\n",
            "Epoch 271/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0467 - val_accuracy: 0.8000 - val_loss: 0.5900\n",
            "Epoch 272/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8000 - val_loss: 0.5931\n",
            "Epoch 273/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.8000 - val_loss: 0.6175\n",
            "Epoch 274/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.8000 - val_loss: 0.6383\n",
            "Epoch 275/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.8000 - val_loss: 0.6487\n",
            "Epoch 276/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8000 - val_loss: 0.6608\n",
            "Epoch 277/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.8000 - val_loss: 0.6679\n",
            "Epoch 278/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.8000 - val_loss: 0.6697\n",
            "Epoch 279/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.8000 - val_loss: 0.6753\n",
            "Epoch 280/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.8000 - val_loss: 0.6819\n",
            "Epoch 281/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8000 - val_loss: 0.6884\n",
            "Epoch 282/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8000 - val_loss: 0.6918\n",
            "Epoch 283/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.8000 - val_loss: 0.6903\n",
            "Epoch 284/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8000 - val_loss: 0.6864\n",
            "Epoch 285/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.8000 - val_loss: 0.6868\n",
            "Epoch 286/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8000 - val_loss: 0.6862\n",
            "Epoch 287/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9422 - loss: 0.0897 - val_accuracy: 0.8000 - val_loss: 0.7043\n",
            "Epoch 288/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8000 - val_loss: 0.7141\n",
            "Epoch 289/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9955 - loss: 0.0094 - val_accuracy: 0.8000 - val_loss: 0.7162\n",
            "Epoch 290/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8000 - val_loss: 0.7007\n",
            "Epoch 291/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8000 - val_loss: 0.6966\n",
            "Epoch 292/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8000 - val_loss: 0.6970\n",
            "Epoch 293/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8000 - val_loss: 0.7050\n",
            "Epoch 294/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8000 - val_loss: 0.7097\n",
            "Epoch 295/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8000 - val_loss: 0.7050\n",
            "Epoch 296/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.8000 - val_loss: 0.6982\n",
            "Epoch 297/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8000 - val_loss: 0.6853\n",
            "Epoch 298/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9611 - loss: 0.0502 - val_accuracy: 0.8000 - val_loss: 0.7390\n",
            "Epoch 299/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.8000 - val_loss: 0.7731\n",
            "Epoch 300/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.8500e-04 - val_accuracy: 0.8000 - val_loss: 0.7843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=300, batch_size=5, validation_split=0.1)\n",
        "model.save('C:/Data/Chatbot/chatbot_model1.h5', hist)\n",
        "print(\"model created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc1cb87",
      "metadata": {
        "id": "0fc1cb87"
      },
      "outputs": [],
      "source": [
        "'''from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "model = load_model('d:/chatbot/chatbot_model.h5')\n",
        "import json\n",
        "import random\n",
        "intents = json.loads(open('d:/chatbot/intents.json').read())\n",
        "words = pickle.load(open('d:/chatbot/words.pkl','rb'))'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7858a89-0e33-4fe1-949c-633bbfd31508",
      "metadata": {
        "id": "e7858a89-0e33-4fe1-949c-633bbfd31508",
        "outputId": "31ab01ce-5b12-4761-a99f-00a4313e7868"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "model = load_model('C:/Data/Chatbot/chatbot_model1.h5')\n",
        "import json\n",
        "import random\n",
        "intents = json.loads(open('C:/Data/intents.json').read())\n",
        "words = pickle.load(open('C:/Data/Chatbot/words.pkl','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc9aab5",
      "metadata": {
        "id": "4dc9aab5"
      },
      "outputs": [],
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern - split words into array\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word - create short form for word\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=True):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - matrix of N words, vocabulary matrix\n",
        "    bag = [0]*len(words)\n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s:\n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % w)\n",
        "    return(np.array(bag))\n",
        "def predict_class(sentence, model):\n",
        "    # filter out predictions below a threshold\n",
        "    p = bow(sentence, words,show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a00c2f",
      "metadata": {
        "id": "c5a00c2f"
      },
      "outputs": [],
      "source": [
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "def chatbot_response(text):\n",
        "    ints = predict_class(text, model)\n",
        "    res = getResponse(ints, intents)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370ab3df-32a5-4dee-b9cc-22a70d8b5cd6",
      "metadata": {
        "id": "370ab3df-32a5-4dee-b9cc-22a70d8b5cd6",
        "outputId": "8cae5382-ec9c-44a0-bde0-b1af67e63299"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter the text: Hi There Pharmacy Hospital blood pressure\n"
          ]
        }
      ],
      "source": [
        "pattern=input(\"Enter the text:\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0a37d0-ea1d-4920-b7f4-723e0ec00b52",
      "metadata": {
        "id": "0f0a37d0-ea1d-4920-b7f4-723e0ec00b52",
        "outputId": "703541f5-6c57-409a-b00c-9621228e6d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'intent': 'greeting', 'probability': '0.9788957'}]"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_class(pattern,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f23aad6-95c4-44b5-acd7-7cb4d0b2c144",
      "metadata": {
        "id": "3f23aad6-95c4-44b5-acd7-7cb4d0b2c144",
        "outputId": "e503a3cb-869a-42d2-fe9d-49f88969a789"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'My pleasure'"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getResponse([{'intent':'thanks','probability':'0.85703474'}],intents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f92c01-898c-4257-b5f6-daeeb7ac7c79",
      "metadata": {
        "id": "96f92c01-898c-4257-b5f6-daeeb7ac7c79",
        "outputId": "4f4755ed-3a91-4e44-baa6-a1d93a1d252f"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter the text: cricket score\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Navigating to Blood Pressure module'"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pattern=input(\"Enter the text:\")\n",
        "chatbot_response(pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec67539",
      "metadata": {
        "id": "8ec67539",
        "outputId": "be52d801-7b19-4d16-d1e3-df679b1536ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
          ]
        }
      ],
      "source": [
        "#Creating GUI with tkinter\n",
        "import tkinter\n",
        "from tkinter import *\n",
        "def send():\n",
        "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
        "    EntryBox.delete(\"0.0\",END)\n",
        "    if msg != '':\n",
        "        ChatLog.config(state=NORMAL)\n",
        "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
        "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
        "        res = chatbot_response(msg)\n",
        "        ChatLog.insert(END, \"Bot: \" + res + '\\n\\n')\n",
        "        ChatLog.config(state=DISABLED)\n",
        "        ChatLog.yview(END)\n",
        "base = Tk()\n",
        "base.title(\"Hello\")\n",
        "base.geometry(\"400x500\")\n",
        "base.resizable(width=FALSE, height=FALSE)\n",
        "#Create Chat window\n",
        "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
        "ChatLog.config(state=DISABLED)\n",
        "#Bind scrollbar to Chat window\n",
        "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
        "ChatLog['yscrollcommand'] = scrollbar.set\n",
        "#Create Button to send message\n",
        "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
        "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
        "                    command= send )\n",
        "#Create the box to enter message\n",
        "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
        "#EntryBox.bind(\"<Return>\", send)\n",
        "#Place all components on the screen\n",
        "scrollbar.place(x=376,y=6, height=386)\n",
        "ChatLog.place(x=6,y=6, height=386, width=370)\n",
        "EntryBox.place(x=128, y=401, height=90, width=265)\n",
        "SendButton.place(x=6, y=401, height=90)\n",
        "base.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e230ff8a-024b-448a-abc5-b31f6cd51152",
      "metadata": {
        "id": "e230ff8a-024b-448a-abc5-b31f6cd51152"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca25bc2-9b0d-4b01-b4ae-04749a8ba191",
      "metadata": {
        "id": "dca25bc2-9b0d-4b01-b4ae-04749a8ba191",
        "outputId": "50414134-9d2c-40bd-e3e3-2c98ece33e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\saurabh\\anaconda3\\lib\\site-packages (1.26.4)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: keras in c:\\users\\saurabh\\anaconda3\\lib\\site-packages (3.8.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\saurabh\\anaconda3\\lib\\site-packages (3.9.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement tkinter (from versions: none)\n",
            "ERROR: No matching distribution found for tkinter\n"
          ]
        }
      ],
      "source": [
        "#pip install numpy keras nltk tkinter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82874ccb-8bf8-4f36-9408-67fd6f50ec72",
      "metadata": {
        "id": "82874ccb-8bf8-4f36-9408-67fd6f50ec72",
        "outputId": "c9ba37e7-5561-4ba5-93a6-8712fbb5e468"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[87], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m chat_window\u001b[38;5;241m.\u001b[39mtag_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbot\u001b[39m\u001b[38;5;124m\"\u001b[39m, foreground\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Run the app\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\tkinter\\__init__.py:1505\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mmainloop(n)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "'''import tkinter as tk\n",
        "from tkinter import Scrollbar\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json\n",
        "\n",
        "# Load model and data\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "model = load_model('C:/Data/Chatbot/chatbot_model.h5')\n",
        "intents = json.loads(open('C:/Data/intents.json').read())\n",
        "words = pickle.load(open('C:/Data/Chatbot/words.pkl', 'rb'))\n",
        "classes = pickle.load(open('C:/Data/Chatbot/words.pkl', 'rb'))  # Ensure this file exists\n",
        "\n",
        "# Function to clean up user input\n",
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# Convert input sentence to bag-of-words\n",
        "def bow(sentence, words, show_details=False):\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag = [0] * len(words)\n",
        "\n",
        "    for s in sentence_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return np.array(bag)\n",
        "\n",
        "# Predict the intent\n",
        "def predict_class(sentence, model):\n",
        "    p = bow(sentence, words, show_details=False)\n",
        "    p = np.array([p])  # Reshape input for model\n",
        "\n",
        "    res = model.predict(p)[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return [{\"intent\": classes[r[0]], \"probability\": str(r[1])} for r in results] if results else []\n",
        "\n",
        "# Get chatbot response\n",
        "def getResponse(ints, intents_json):\n",
        "    if not ints:\n",
        "        return \"I'm sorry, I didn't understand that. Can you rephrase?\"\n",
        "\n",
        "    tag = ints[0]['intent']\n",
        "    for i in intents_json['intents']:\n",
        "        if i['tag'] == tag:\n",
        "            return random.choice(i['responses'])\n",
        "\n",
        "    return \"I'm sorry, I didn't understand that. Can you rephrase?\"\n",
        "\n",
        "# Chatbot response function\n",
        "def chatbot_response(text):\n",
        "    ints = predict_class(text, model)\n",
        "    return getResponse(ints, intents)\n",
        "\n",
        "# GUI function\n",
        "def send_message():\n",
        "    msg = user_input.get()\n",
        "    if msg.strip():  # Ensure input is not empty\n",
        "        chat_window.config(state=tk.NORMAL)\n",
        "        chat_window.insert(tk.END, \"You: \" + msg + \"\\n\", \"user\")\n",
        "\n",
        "        res = chatbot_response(msg)\n",
        "        chat_window.insert(tk.END, \"Bot: \" + res + \"\\n\", \"bot\")\n",
        "\n",
        "        chat_window.config(state=tk.DISABLED)\n",
        "        user_input.delete(0, tk.END)  # Clear input field\n",
        "        chat_window.yview(tk.END)  # Auto-scroll\n",
        "\n",
        "# Create GUI\n",
        "root = tk.Tk()\n",
        "root.title(\"Chatbot\")\n",
        "root.geometry(\"400x500\")\n",
        "root.resizable(False, False)\n",
        "\n",
        "# Chat window\n",
        "chat_window = tk.Text(root, bd=1, bg=\"white\", font=(\"Arial\", 12), wrap=tk.WORD)\n",
        "chat_window.config(state=tk.DISABLED)\n",
        "chat_window.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
        "\n",
        "# Scrollbar\n",
        "scrollbar = Scrollbar(chat_window)\n",
        "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
        "chat_window.config(yscrollcommand=scrollbar.set)\n",
        "scrollbar.config(command=chat_window.yview)\n",
        "\n",
        "# Input field\n",
        "user_input = tk.Entry(root, bd=1, font=(\"Arial\", 12))\n",
        "user_input.pack(padx=10, pady=5, fill=tk.X)\n",
        "\n",
        "# Send button\n",
        "send_button = tk.Button(root, text=\"Send\", font=(\"Arial\", 12, \"bold\"), command=send_message)\n",
        "send_button.pack(pady=5)\n",
        "\n",
        "# Tags for formatting\n",
        "chat_window.tag_config(\"user\", foreground=\"blue\", font=(\"Arial\", 12, \"bold\"))\n",
        "chat_window.tag_config(\"bot\", foreground=\"green\", font=(\"Arial\", 12))\n",
        "\n",
        "# Run the app\n",
        "root.mainloop()'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c3483c-1581-4071-877a-d03081c49fc2",
      "metadata": {
        "id": "38c3483c-1581-4071-877a-d03081c49fc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}